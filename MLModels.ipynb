{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "39b78f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import tsgm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d83ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be27e30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AmplitudePrimary</th>\n",
       "      <th>AmplitudeSecondary</th>\n",
       "      <th>Latency</th>\n",
       "      <th>CorrectiveSaccade</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.905335</td>\n",
       "      <td>0.907229</td>\n",
       "      <td>0.124998</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.381435</td>\n",
       "      <td>0.563108</td>\n",
       "      <td>0.341670</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.415535</td>\n",
       "      <td>1.097195</td>\n",
       "      <td>0.308346</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.173487</td>\n",
       "      <td>1.182019</td>\n",
       "      <td>0.175026</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.801426</td>\n",
       "      <td>7.733378</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3.948713</td>\n",
       "      <td>3.948713</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>14.329194</td>\n",
       "      <td>3.160185</td>\n",
       "      <td>0.125025</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>19.042962</td>\n",
       "      <td>3.035957</td>\n",
       "      <td>0.525034</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.762336</td>\n",
       "      <td>2.942543</td>\n",
       "      <td>0.325038</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>31.529303</td>\n",
       "      <td>1.850806</td>\n",
       "      <td>0.508392</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AmplitudePrimary  AmplitudeSecondary   Latency  CorrectiveSaccade  Normal\n",
       "0            7.905335            0.907229  0.124998                  7       0\n",
       "1           17.381435            0.563108  0.341670                 13       0\n",
       "2           29.415535            1.097195  0.308346                 16       0\n",
       "3           10.173487            1.182019  0.175026                  9       0\n",
       "4            6.801426            7.733378  0.391700                 28       0\n",
       "..                ...                 ...       ...                ...     ...\n",
       "187          3.948713            3.948713  0.033335                 16       1\n",
       "188         14.329194            3.160185  0.125025                  6       1\n",
       "189         19.042962            3.035957  0.525034                  5       1\n",
       "190          1.762336            2.942543  0.325038                 15       1\n",
       "191         31.529303            1.850806  0.508392                 20       1\n",
       "\n",
       "[192 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"TestDataCompiled.csv\")\n",
    "df.columns = ['AmplitudePrimary', 'AmplitudeSecondary', 'Latency', \"CorrectiveSaccade\", \"Normal\"]\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81402f19",
   "metadata": {},
   "source": [
    "# No Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c05b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Normal\n",
    "X = df.drop('Normal', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86ebb8",
   "metadata": {},
   "source": [
    "### Logsitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25264ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717948717948718\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83        28\n",
      "           1       0.50      0.09      0.15        11\n",
      "\n",
      "    accuracy                           0.72        39\n",
      "   macro avg       0.61      0.53      0.49        39\n",
      "weighted avg       0.66      0.72      0.64        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e72667",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda3ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7692307692307693\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85        28\n",
      "           1       0.67      0.36      0.47        11\n",
      "\n",
      "    accuracy                           0.77        39\n",
      "   macro avg       0.73      0.65      0.66        39\n",
      "weighted avg       0.75      0.77      0.74        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_depth = None, n_estimators = 300, min_samples_leaf = 4, min_samples_split = 10)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde0098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best Score: 0.7053763440860215\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b222e",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b91f240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 1}\n",
      "Best Score: 0.7124731182795699\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],           # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]   # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "#     'kernel': ['rbf', 'poly', 'linear']  # Kernel type\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74cc4e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717948717948718\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        28\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.72        39\n",
      "   macro avg       0.36      0.50      0.42        39\n",
      "weighted avg       0.52      0.72      0.60        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanmatichoudhary/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanmatichoudhary/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanmatichoudhary/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', random_state=42, C = 0.1, gamma = 1)  # You can choose different kernels such as 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65f631",
   "metadata": {},
   "source": [
    "### simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a854d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 1s 5ms/step - loss: 1.4888 - accuracy: 0.5820 - val_loss: 0.8936 - val_accuracy: 0.7097\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7295 - val_loss: 0.5963 - val_accuracy: 0.7742\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.7049 - val_loss: 0.6013 - val_accuracy: 0.7419\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7295 - val_loss: 0.5773 - val_accuracy: 0.7097\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7377 - val_loss: 0.5926 - val_accuracy: 0.7097\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7295 - val_loss: 0.5878 - val_accuracy: 0.7097\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7377 - val_loss: 0.5849 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6967 - val_loss: 0.6046 - val_accuracy: 0.7742\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7459 - val_loss: 0.5926 - val_accuracy: 0.7097\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7377 - val_loss: 0.6126 - val_accuracy: 0.7097\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7377 - val_loss: 0.6113 - val_accuracy: 0.7097\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7295 - val_loss: 0.5964 - val_accuracy: 0.7097\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7459 - val_loss: 0.6103 - val_accuracy: 0.7097\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7541 - val_loss: 0.6131 - val_accuracy: 0.7097\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7377 - val_loss: 0.5994 - val_accuracy: 0.7097\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7623 - val_loss: 0.6210 - val_accuracy: 0.7097\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7459 - val_loss: 0.6275 - val_accuracy: 0.7419\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7459 - val_loss: 0.6044 - val_accuracy: 0.7097\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7541 - val_loss: 0.6157 - val_accuracy: 0.7097\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7459 - val_loss: 0.6336 - val_accuracy: 0.7419\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7377 - val_loss: 0.6154 - val_accuracy: 0.7097\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7623 - val_loss: 0.6097 - val_accuracy: 0.7097\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7459 - val_loss: 0.6498 - val_accuracy: 0.7419\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7705 - val_loss: 0.6054 - val_accuracy: 0.7097\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7295 - val_loss: 0.6133 - val_accuracy: 0.7097\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7623 - val_loss: 0.6084 - val_accuracy: 0.7419\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7787 - val_loss: 0.6152 - val_accuracy: 0.7097\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7705 - val_loss: 0.6138 - val_accuracy: 0.7097\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7459 - val_loss: 0.6269 - val_accuracy: 0.7097\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7377 - val_loss: 0.6437 - val_accuracy: 0.7097\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7377 - val_loss: 0.6204 - val_accuracy: 0.7097\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7459 - val_loss: 0.6225 - val_accuracy: 0.7097\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7705 - val_loss: 0.6219 - val_accuracy: 0.7097\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7787 - val_loss: 0.6172 - val_accuracy: 0.7097\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7459 - val_loss: 0.6360 - val_accuracy: 0.7419\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7623 - val_loss: 0.6333 - val_accuracy: 0.7097\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7541 - val_loss: 0.6520 - val_accuracy: 0.7419\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7541 - val_loss: 0.6282 - val_accuracy: 0.7097\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7705 - val_loss: 0.6301 - val_accuracy: 0.7097\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7623 - val_loss: 0.6596 - val_accuracy: 0.7419\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7623 - val_loss: 0.6665 - val_accuracy: 0.7097\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7623 - val_loss: 0.6569 - val_accuracy: 0.7419\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7459 - val_loss: 0.6500 - val_accuracy: 0.7419\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7787 - val_loss: 0.6780 - val_accuracy: 0.7097\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7541 - val_loss: 0.6926 - val_accuracy: 0.6774\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7623 - val_loss: 0.6590 - val_accuracy: 0.7097\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7623 - val_loss: 0.6422 - val_accuracy: 0.7097\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7787 - val_loss: 0.6737 - val_accuracy: 0.7097\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7705 - val_loss: 0.6455 - val_accuracy: 0.7419\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7623 - val_loss: 0.6620 - val_accuracy: 0.7419\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6923\n",
      "Test Loss: 0.6320127844810486, Test Accuracy: 0.692307710647583\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(4,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=4, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fad781",
   "metadata": {},
   "source": [
    "# Data Augmentation: Gaussain Noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3da10f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(X, mean=0, std=0.1):\n",
    "    noise = np.random.normal(mean, std, size=X.shape)\n",
    "    return X + noise\n",
    "# Example: Adding Gaussian noise with mean=0 and std=0.1\n",
    "X_with_gaussian_noise = add_gaussian_noise(X)\n",
    "X_augmented = pd.concat([X, X_with_gaussian_noise])\n",
    "y_augmented = pd.concat([y,y])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42, stratify = y_augmented)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc8196",
   "metadata": {},
   "source": [
    "### Logisitic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "730727e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7402597402597403\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84        55\n",
      "           1       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.74        77\n",
      "   macro avg       0.69      0.59      0.59        77\n",
      "weighted avg       0.72      0.74      0.69        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b7d7d",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f2034c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Score: 0.8013749338974089\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d36e53b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91        55\n",
      "           1       0.87      0.59      0.70        22\n",
      "\n",
      "    accuracy                           0.86        77\n",
      "   macro avg       0.86      0.78      0.80        77\n",
      "weighted avg       0.86      0.86      0.85        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_depth = 10, n_estimators = 300, min_samples_leaf = 1, min_samples_split = 2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f99e8",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32424617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 1}\n",
      "Best Score: 0.889264939185616\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],           # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]   # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "#     'kernel': ['rbf', 'poly', 'linear']  # Kernel type\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6aed1fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922077922077922\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95        55\n",
      "           1       0.90      0.82      0.86        22\n",
      "\n",
      "    accuracy                           0.92        77\n",
      "   macro avg       0.91      0.89      0.90        77\n",
      "weighted avg       0.92      0.92      0.92        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', random_state=42, C = 10, gamma = 1)  # You can choose different kernels such as 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078f617",
   "metadata": {},
   "source": [
    "### simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7cb4e5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 1s 3ms/step - loss: 0.7556 - accuracy: 0.6571 - val_loss: 0.5756 - val_accuracy: 0.6129\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.6816 - val_loss: 0.5203 - val_accuracy: 0.7581\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.7143 - val_loss: 0.5317 - val_accuracy: 0.7903\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7224 - val_loss: 0.5279 - val_accuracy: 0.8065\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7347 - val_loss: 0.5238 - val_accuracy: 0.8065\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7306 - val_loss: 0.5691 - val_accuracy: 0.7097\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7184 - val_loss: 0.5333 - val_accuracy: 0.8065\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7306 - val_loss: 0.7031 - val_accuracy: 0.6452\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6735 - val_loss: 0.5643 - val_accuracy: 0.7742\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.7347 - val_loss: 0.5078 - val_accuracy: 0.7903\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.7061 - val_loss: 0.6131 - val_accuracy: 0.6935\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.6980 - val_loss: 0.5260 - val_accuracy: 0.7903\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.6857 - val_loss: 0.5228 - val_accuracy: 0.7903\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7265 - val_loss: 0.5102 - val_accuracy: 0.7742\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7347 - val_loss: 0.5156 - val_accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7347 - val_loss: 0.5501 - val_accuracy: 0.7742\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7224 - val_loss: 0.5096 - val_accuracy: 0.7742\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.6939 - val_loss: 0.5040 - val_accuracy: 0.7742\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7184 - val_loss: 0.5652 - val_accuracy: 0.7581\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7184 - val_loss: 0.5051 - val_accuracy: 0.7581\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7469 - val_loss: 0.5520 - val_accuracy: 0.7903\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7347 - val_loss: 0.5448 - val_accuracy: 0.7581\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7143 - val_loss: 0.5289 - val_accuracy: 0.7742\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7633 - val_loss: 0.5403 - val_accuracy: 0.7581\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7429 - val_loss: 0.5132 - val_accuracy: 0.7742\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.7510 - val_loss: 0.5447 - val_accuracy: 0.7742\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7551 - val_loss: 0.5403 - val_accuracy: 0.7742\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7347 - val_loss: 0.5438 - val_accuracy: 0.7581\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7551 - val_loss: 0.5751 - val_accuracy: 0.7581\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7755 - val_loss: 0.5520 - val_accuracy: 0.7581\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7388 - val_loss: 0.5859 - val_accuracy: 0.7419\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7714 - val_loss: 0.5372 - val_accuracy: 0.7903\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7592 - val_loss: 0.5489 - val_accuracy: 0.7742\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7755 - val_loss: 0.5585 - val_accuracy: 0.7903\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7714 - val_loss: 0.5362 - val_accuracy: 0.7581\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7510 - val_loss: 0.5576 - val_accuracy: 0.7742\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7429 - val_loss: 0.5187 - val_accuracy: 0.7581\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7510 - val_loss: 0.5976 - val_accuracy: 0.7419\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7020 - val_loss: 0.5454 - val_accuracy: 0.7581\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7633 - val_loss: 0.5556 - val_accuracy: 0.7742\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7755 - val_loss: 0.5729 - val_accuracy: 0.7742\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7755 - val_loss: 0.5471 - val_accuracy: 0.7581\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7510 - val_loss: 0.5740 - val_accuracy: 0.7742\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7755 - val_loss: 0.5530 - val_accuracy: 0.7742\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7592 - val_loss: 0.5313 - val_accuracy: 0.7581\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7551 - val_loss: 0.5894 - val_accuracy: 0.7581\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7592 - val_loss: 0.5636 - val_accuracy: 0.7903\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7633 - val_loss: 0.5536 - val_accuracy: 0.7742\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7755 - val_loss: 0.5642 - val_accuracy: 0.7742\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7592 - val_loss: 0.5375 - val_accuracy: 0.7581\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.7273\n",
      "Test Loss: 0.6387169361114502, Test Accuracy: 0.7272727489471436\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(4,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=4, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a16708",
   "metadata": {},
   "source": [
    "# Data Augmentation: Jittering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79ee70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jittering(X, magnitude=0.1):\n",
    "    jitter = np.random.uniform(-magnitude, magnitude, size=X.shape)\n",
    "    return X + jitter\n",
    "\n",
    "# Example: Adding jittering with magnitude=0.1\n",
    "X_with_jittering = add_jittering(X)\n",
    "\n",
    "X_augmented = pd.concat([X, X_with_jittering])\n",
    "y_augmented = pd.concat([y,y])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42, stratify = y_augmented)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd0798",
   "metadata": {},
   "source": [
    "### Logisitic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c68ed7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7402597402597403\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84        55\n",
      "           1       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.74        77\n",
      "   macro avg       0.69      0.59      0.59        77\n",
      "weighted avg       0.72      0.74      0.69        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0576e7d",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e903655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.8079851930195664\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "084256e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91        55\n",
      "           1       0.87      0.59      0.70        22\n",
      "\n",
      "    accuracy                           0.86        77\n",
      "   macro avg       0.86      0.78      0.80        77\n",
      "weighted avg       0.86      0.86      0.85        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_depth = 10, n_estimators = 100, min_samples_leaf = 1, min_samples_split = 2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60793485",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eaf26dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 1}\n",
      "Best Score: 0.889264939185616\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],           # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]   # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "#     'kernel': ['rbf', 'poly', 'linear']  # Kernel type\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8657aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922077922077922\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95        55\n",
      "           1       0.90      0.82      0.86        22\n",
      "\n",
      "    accuracy                           0.92        77\n",
      "   macro avg       0.91      0.89      0.90        77\n",
      "weighted avg       0.92      0.92      0.92        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', random_state=42, C = 10, gamma = 1)  # You can choose different kernels such as 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf1b519",
   "metadata": {},
   "source": [
    "### simple neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8286bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6857 - val_loss: 0.5222 - val_accuracy: 0.7581\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7184 - val_loss: 0.5025 - val_accuracy: 0.7581\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7020 - val_loss: 0.5637 - val_accuracy: 0.7581\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7429 - val_loss: 0.5849 - val_accuracy: 0.7419\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7184 - val_loss: 0.5087 - val_accuracy: 0.7742\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7184 - val_loss: 0.5380 - val_accuracy: 0.7742\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7429 - val_loss: 0.5218 - val_accuracy: 0.7581\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7469 - val_loss: 0.5546 - val_accuracy: 0.7581\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7388 - val_loss: 0.5363 - val_accuracy: 0.7742\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7347 - val_loss: 0.6574 - val_accuracy: 0.7742\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7388 - val_loss: 0.5328 - val_accuracy: 0.7742\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7429 - val_loss: 0.5361 - val_accuracy: 0.7742\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7429 - val_loss: 0.5666 - val_accuracy: 0.7742\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7469 - val_loss: 0.5405 - val_accuracy: 0.7581\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7551 - val_loss: 0.5649 - val_accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7633 - val_loss: 0.5886 - val_accuracy: 0.7581\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7551 - val_loss: 0.5648 - val_accuracy: 0.7581\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.7510 - val_loss: 0.6010 - val_accuracy: 0.7419\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7510 - val_loss: 0.6441 - val_accuracy: 0.7581\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7673 - val_loss: 0.5571 - val_accuracy: 0.7742\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7388 - val_loss: 0.5906 - val_accuracy: 0.7581\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7796 - val_loss: 0.6226 - val_accuracy: 0.7258\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7633 - val_loss: 0.6066 - val_accuracy: 0.7581\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7633 - val_loss: 0.6407 - val_accuracy: 0.7258\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7837 - val_loss: 0.7225 - val_accuracy: 0.7258\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7510 - val_loss: 0.6123 - val_accuracy: 0.7742\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7551 - val_loss: 0.5779 - val_accuracy: 0.7742\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7306 - val_loss: 0.5758 - val_accuracy: 0.7581\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7510 - val_loss: 0.7676 - val_accuracy: 0.6613\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7510 - val_loss: 0.5830 - val_accuracy: 0.7742\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7755 - val_loss: 0.5711 - val_accuracy: 0.7742\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7102 - val_loss: 0.5897 - val_accuracy: 0.7581\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7633 - val_loss: 0.5941 - val_accuracy: 0.7581\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7469 - val_loss: 0.6115 - val_accuracy: 0.7581\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7551 - val_loss: 0.6016 - val_accuracy: 0.7419\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7796 - val_loss: 0.6086 - val_accuracy: 0.7419\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7633 - val_loss: 0.6321 - val_accuracy: 0.7419\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7592 - val_loss: 0.5914 - val_accuracy: 0.7419\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7592 - val_loss: 0.5732 - val_accuracy: 0.7581\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7469 - val_loss: 0.5982 - val_accuracy: 0.7581\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7673 - val_loss: 0.5882 - val_accuracy: 0.7581\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7755 - val_loss: 0.6406 - val_accuracy: 0.7581\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7551 - val_loss: 0.5840 - val_accuracy: 0.7742\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7388 - val_loss: 0.5834 - val_accuracy: 0.7742\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7633 - val_loss: 0.5833 - val_accuracy: 0.7581\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7633 - val_loss: 0.6031 - val_accuracy: 0.7419\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7796 - val_loss: 0.6105 - val_accuracy: 0.7419\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7469 - val_loss: 0.5868 - val_accuracy: 0.7581\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7633 - val_loss: 0.6051 - val_accuracy: 0.7581\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7714 - val_loss: 0.6148 - val_accuracy: 0.7581\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.6883\n",
      "Test Loss: 0.6772850751876831, Test Accuracy: 0.6883116960525513\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(4,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=4, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e323fd89",
   "metadata": {},
   "source": [
    "# Data Augmentation: GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d92092ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "Epoch: 0, Discriminator Loss: 0.7228303551673889, Generator Loss: 0.7351122498512268\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 1, Discriminator Loss: 1.0624488592147827, Generator Loss: 0.7233213186264038\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoch: 2, Discriminator Loss: 1.9973974227905273, Generator Loss: 0.7383577823638916\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 3, Discriminator Loss: 1.1451380252838135, Generator Loss: 0.6589908003807068\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 4, Discriminator Loss: 1.6089630126953125, Generator Loss: 0.6887204647064209\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 5, Discriminator Loss: 1.3649269342422485, Generator Loss: 0.6910362243652344\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 6, Discriminator Loss: 1.1417568922042847, Generator Loss: 0.7382432222366333\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 7, Discriminator Loss: 0.7862991094589233, Generator Loss: 0.6943045854568481\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoch: 8, Discriminator Loss: 1.786177635192871, Generator Loss: 0.7400085926055908\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 9, Discriminator Loss: 1.4998925924301147, Generator Loss: 0.6759654879570007\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 10, Discriminator Loss: 2.1165621280670166, Generator Loss: 0.6691427230834961\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 11, Discriminator Loss: 0.94856858253479, Generator Loss: 0.7454179525375366\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 12, Discriminator Loss: 1.5533655881881714, Generator Loss: 0.6629080176353455\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 13, Discriminator Loss: 1.2264331579208374, Generator Loss: 0.739252507686615\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 14, Discriminator Loss: 0.6705472469329834, Generator Loss: 0.728166937828064\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 15, Discriminator Loss: 1.6706008911132812, Generator Loss: 0.6758178472518921\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 16, Discriminator Loss: 2.0292139053344727, Generator Loss: 0.6771084070205688\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 17, Discriminator Loss: 0.3879774808883667, Generator Loss: 0.7031288146972656\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 18, Discriminator Loss: 1.4039993286132812, Generator Loss: 0.7254235744476318\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 19, Discriminator Loss: 2.290621042251587, Generator Loss: 0.7119411826133728\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 20, Discriminator Loss: 0.5588744878768921, Generator Loss: 0.7355296611785889\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 21, Discriminator Loss: 1.554403305053711, Generator Loss: 0.7168411016464233\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 22, Discriminator Loss: 0.87619948387146, Generator Loss: 0.665776252746582\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 23, Discriminator Loss: 0.8605527877807617, Generator Loss: 0.6757570505142212\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 24, Discriminator Loss: 1.1824294328689575, Generator Loss: 0.6713410019874573\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 25, Discriminator Loss: 1.0391616821289062, Generator Loss: 0.7386069893836975\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 26, Discriminator Loss: 0.7114676237106323, Generator Loss: 0.67909836769104\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 27, Discriminator Loss: 1.075193166732788, Generator Loss: 0.6887025237083435\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 28, Discriminator Loss: 2.311594247817993, Generator Loss: 0.669037401676178\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 29, Discriminator Loss: 2.2496559619903564, Generator Loss: 0.6954385042190552\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 30, Discriminator Loss: 0.9718559980392456, Generator Loss: 0.658137321472168\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 31, Discriminator Loss: 0.6767390966415405, Generator Loss: 0.7182943224906921\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 32, Discriminator Loss: 0.9332778453826904, Generator Loss: 0.6702384948730469\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 33, Discriminator Loss: 1.4661407470703125, Generator Loss: 0.6809329986572266\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 34, Discriminator Loss: 1.0099496841430664, Generator Loss: 0.7420664429664612\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 35, Discriminator Loss: 0.7608349323272705, Generator Loss: 0.7707636952400208\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 36, Discriminator Loss: 1.8764457702636719, Generator Loss: 0.7303054332733154\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 37, Discriminator Loss: 0.7409297227859497, Generator Loss: 0.7201473116874695\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 38, Discriminator Loss: 0.8037258386611938, Generator Loss: 0.7276731729507446\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 39, Discriminator Loss: 1.8625390529632568, Generator Loss: 0.6795259714126587\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 40, Discriminator Loss: 0.9290608167648315, Generator Loss: 0.7193915843963623\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 41, Discriminator Loss: 0.6320635080337524, Generator Loss: 0.7348692417144775\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 42, Discriminator Loss: 1.8194098472595215, Generator Loss: 0.6685202717781067\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 43, Discriminator Loss: 1.6916900873184204, Generator Loss: 0.7599501013755798\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 44, Discriminator Loss: 0.9236463904380798, Generator Loss: 0.665482223033905\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 45, Discriminator Loss: 1.3556500673294067, Generator Loss: 0.7320734262466431\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 46, Discriminator Loss: 1.6571413278579712, Generator Loss: 0.6370977163314819\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 47, Discriminator Loss: 1.0449057817459106, Generator Loss: 0.7068492770195007\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 48, Discriminator Loss: 1.1057121753692627, Generator Loss: 0.6767392158508301\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 49, Discriminator Loss: 1.223496437072754, Generator Loss: 0.6781612634658813\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 50, Discriminator Loss: 0.9508222937583923, Generator Loss: 0.7370160818099976\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 51, Discriminator Loss: 1.1371500492095947, Generator Loss: 0.6790812015533447\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 52, Discriminator Loss: 1.5006978511810303, Generator Loss: 0.6961114406585693\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 53, Discriminator Loss: 0.9964332580566406, Generator Loss: 0.7137290239334106\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 54, Discriminator Loss: 2.749526023864746, Generator Loss: 0.6905019283294678\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 55, Discriminator Loss: 0.8843117952346802, Generator Loss: 0.7209986448287964\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 56, Discriminator Loss: 0.717960000038147, Generator Loss: 0.7008823156356812\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 57, Discriminator Loss: 0.8932167291641235, Generator Loss: 0.6611424684524536\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 58, Discriminator Loss: 1.3392951488494873, Generator Loss: 0.6752421855926514\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 59, Discriminator Loss: 0.9666216969490051, Generator Loss: 0.6645034551620483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 60, Discriminator Loss: 0.8029500842094421, Generator Loss: 0.7505884170532227\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 61, Discriminator Loss: 1.2901699542999268, Generator Loss: 0.7014097571372986\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 62, Discriminator Loss: 1.5939209461212158, Generator Loss: 0.6785833835601807\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 63, Discriminator Loss: 0.8600170612335205, Generator Loss: 0.7481177449226379\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 64, Discriminator Loss: 0.6407102942466736, Generator Loss: 0.7048909664154053\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 65, Discriminator Loss: 1.0071110725402832, Generator Loss: 0.6994690895080566\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 66, Discriminator Loss: 0.7979354858398438, Generator Loss: 0.7062640190124512\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 67, Discriminator Loss: 0.8354490399360657, Generator Loss: 0.6538369655609131\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 68, Discriminator Loss: 1.4671686887741089, Generator Loss: 0.7665556073188782\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 69, Discriminator Loss: 1.0260266065597534, Generator Loss: 0.7038971781730652\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 70, Discriminator Loss: 1.0270835161209106, Generator Loss: 0.7160542011260986\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 71, Discriminator Loss: 1.0549044609069824, Generator Loss: 0.6572940945625305\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 72, Discriminator Loss: 0.9443174600601196, Generator Loss: 0.6713047027587891\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 73, Discriminator Loss: 0.53908771276474, Generator Loss: 0.6398184895515442\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 74, Discriminator Loss: 1.4999415874481201, Generator Loss: 0.6739591360092163\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 75, Discriminator Loss: 0.6240760684013367, Generator Loss: 0.6998550295829773\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 76, Discriminator Loss: 0.7288646101951599, Generator Loss: 0.7270604372024536\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 77, Discriminator Loss: 1.9587955474853516, Generator Loss: 0.667647659778595\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 78, Discriminator Loss: 1.4329692125320435, Generator Loss: 0.7101656198501587\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 79, Discriminator Loss: 1.827426791191101, Generator Loss: 0.6990976333618164\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 80, Discriminator Loss: 1.04292893409729, Generator Loss: 0.7105398178100586\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 81, Discriminator Loss: 1.4139703512191772, Generator Loss: 0.6875735521316528\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 82, Discriminator Loss: 1.582041621208191, Generator Loss: 0.6821896433830261\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 83, Discriminator Loss: 2.174111843109131, Generator Loss: 0.720534086227417\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 84, Discriminator Loss: 1.6924883127212524, Generator Loss: 0.7094213962554932\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 85, Discriminator Loss: 0.9483602046966553, Generator Loss: 0.719454824924469\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 86, Discriminator Loss: 1.4075602293014526, Generator Loss: 0.6922367215156555\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 87, Discriminator Loss: 0.5921107530593872, Generator Loss: 0.6875636577606201\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 88, Discriminator Loss: 1.6271988153457642, Generator Loss: 0.6726120710372925\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 89, Discriminator Loss: 0.7239965796470642, Generator Loss: 0.661441445350647\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 90, Discriminator Loss: 1.4967186450958252, Generator Loss: 0.6947715282440186\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 91, Discriminator Loss: 2.23384952545166, Generator Loss: 0.7258636951446533\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 92, Discriminator Loss: 0.5996732711791992, Generator Loss: 0.683850884437561\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 93, Discriminator Loss: 1.9518725872039795, Generator Loss: 0.6665644645690918\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 94, Discriminator Loss: 4.485276699066162, Generator Loss: 0.698197603225708\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 95, Discriminator Loss: 1.7348226308822632, Generator Loss: 0.721896767616272\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 96, Discriminator Loss: 1.4456348419189453, Generator Loss: 0.7014961242675781\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 97, Discriminator Loss: 1.376253366470337, Generator Loss: 0.7058371305465698\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 98, Discriminator Loss: 1.0871117115020752, Generator Loss: 0.7049544453620911\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Epoch: 99, Discriminator Loss: 2.313645362854004, Generator Loss: 0.7131084203720093\n",
      "32/32 [==============================] - 0s 852us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5945975 , 0.69924504, 0.68782675, 0.47292876],\n",
       "       [0.5098404 , 0.791132  , 0.8448489 , 0.24682622],\n",
       "       [0.7744844 , 0.79168385, 0.28674114, 0.4047448 ],\n",
       "       ...,\n",
       "       [0.33966556, 0.837537  , 0.5905928 , 0.77881265],\n",
       "       [0.69391423, 0.52821773, 0.10553468, 0.14630388],\n",
       "       [0.60785675, 0.10906217, 0.31993917, 0.18274663]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Generator network\n",
    "def build_generator(latent_dim, num_features):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=latent_dim),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(num_features, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Updated discriminator network with additional layers and dropout\n",
    "def build_discriminator(num_features):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation='relu', input_dim=num_features),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = keras.Sequential([generator, discriminator])\n",
    "    return model\n",
    "\n",
    "# Training GAN\n",
    "def train_gan(generator, discriminator, gan, X_train, y_train, latent_dim, num_epochs=100, batch_size=4, logging_interval=1000):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Generate fake samples\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        generated_data = generator.predict(noise)\n",
    "        \n",
    "        # Select a random batch of real samples\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_samples = X_train.iloc[idx]\n",
    "        \n",
    "        # Concatenate real and fake samples\n",
    "        X = np.concatenate([real_samples, generated_data])\n",
    "        \n",
    "        # Labels for real and fake samples\n",
    "        y_real = np.ones((batch_size, 1))\n",
    "        y_fake = np.zeros((batch_size, 1))\n",
    "        y = np.concatenate([y_real, y_fake])\n",
    "        \n",
    "        # Train discriminator\n",
    "        discriminator_loss = discriminator.train_on_batch(X, y)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        generator_loss = gan.train_on_batch(noise, y_real)\n",
    "        \n",
    "        # Logging\n",
    "#         if epoch % logging_interval == 0:\n",
    "        print(f\"Epoch: {epoch}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")\n",
    "\n",
    "# Generate synthetic samples\n",
    "def generate_samples(generator, latent_dim, num_samples):\n",
    "    noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "    generated_data = generator.predict(noise)\n",
    "    return generated_data\n",
    "\n",
    "# Load data\n",
    "# Assuming your DataFrame is named df, and the target column is named 'abnormal'\n",
    "# Drop the target column to get the feature data\n",
    "# X = df.drop(columns=['normal']).values\n",
    "# y = df['normal'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Parameters\n",
    "latent_dim = 100\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Build and compile models\n",
    "generator = build_generator(latent_dim, num_features)\n",
    "discriminator = build_discriminator(num_features)\n",
    "gan = build_gan(generator, discriminator)\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "discriminator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "# discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train GAN\n",
    "train_gan(generator, discriminator, gan, X_train, y_train, latent_dim)\n",
    "\n",
    "# Generate samples\n",
    "generated_samples = generate_samples(generator, latent_dim, 1000)\n",
    "\n",
    "# Plot generated samples\n",
    "# plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], color='blue', alpha=0.5, label='Real Data')\n",
    "# plt.scatter(generated_samples[:, 0], generated_samples[:, 1], color='red', alpha=0.5, label='Generated Data')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "display(generated_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc964323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], color='blue', alpha=0.5, label='Real Data')\n",
    "plt.scatter(generated_samples[:, 0], generated_samples[:, 1], color='red', alpha=0.5, label='Generated Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee5c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
