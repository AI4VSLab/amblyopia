{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b78f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 20:25:42.354740: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import tsgm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d83ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be27e30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AmplitudePrimary</th>\n",
       "      <th>AmplitudeSecondary</th>\n",
       "      <th>Latency</th>\n",
       "      <th>CorrectiveSaccade</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.905335</td>\n",
       "      <td>0.907229</td>\n",
       "      <td>0.124998</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.381435</td>\n",
       "      <td>0.563108</td>\n",
       "      <td>0.341670</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.415535</td>\n",
       "      <td>1.097195</td>\n",
       "      <td>0.308346</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.173487</td>\n",
       "      <td>1.182019</td>\n",
       "      <td>0.175026</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.801426</td>\n",
       "      <td>7.733378</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3.948713</td>\n",
       "      <td>3.948713</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>14.329194</td>\n",
       "      <td>3.160185</td>\n",
       "      <td>0.125025</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>19.042962</td>\n",
       "      <td>3.035957</td>\n",
       "      <td>0.525034</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.762336</td>\n",
       "      <td>2.942543</td>\n",
       "      <td>0.325038</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>31.529303</td>\n",
       "      <td>1.850806</td>\n",
       "      <td>0.508392</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AmplitudePrimary  AmplitudeSecondary   Latency  CorrectiveSaccade  Normal\n",
       "0            7.905335            0.907229  0.124998                  7       0\n",
       "1           17.381435            0.563108  0.341670                 13       0\n",
       "2           29.415535            1.097195  0.308346                 16       0\n",
       "3           10.173487            1.182019  0.175026                  9       0\n",
       "4            6.801426            7.733378  0.391700                 28       0\n",
       "..                ...                 ...       ...                ...     ...\n",
       "187          3.948713            3.948713  0.033335                 16       1\n",
       "188         14.329194            3.160185  0.125025                  6       1\n",
       "189         19.042962            3.035957  0.525034                  5       1\n",
       "190          1.762336            2.942543  0.325038                 15       1\n",
       "191         31.529303            1.850806  0.508392                 20       1\n",
       "\n",
       "[192 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Normal\n",
       "0    137\n",
       "1     55\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"TestDataCompiled.csv\")\n",
    "df.columns = ['AmplitudePrimary', 'AmplitudeSecondary', 'Latency', \"CorrectiveSaccade\", \"Normal\"]\n",
    "display(df)\n",
    "df[\"Normal\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81402f19",
   "metadata": {},
   "source": [
    "# No Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c05b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Normal\n",
    "X = df.drop('Normal', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86ebb8",
   "metadata": {},
   "source": [
    "### Logsitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25264ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717948717948718\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83        28\n",
      "           1       0.50      0.09      0.15        11\n",
      "\n",
      "    accuracy                           0.72        39\n",
      "   macro avg       0.61      0.53      0.49        39\n",
      "weighted avg       0.66      0.72      0.64        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "306f0b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "141    1\n",
       "21     0\n",
       "118    0\n",
       "63     0\n",
       "139    1\n",
       "99     0\n",
       "145    1\n",
       "92     0\n",
       "2      0\n",
       "128    0\n",
       "29     0\n",
       "37     0\n",
       "52     0\n",
       "126    0\n",
       "32     0\n",
       "71     0\n",
       "116    0\n",
       "74     0\n",
       "102    0\n",
       "131    0\n",
       "103    0\n",
       "163    1\n",
       "23     0\n",
       "107    0\n",
       "173    1\n",
       "14     0\n",
       "136    0\n",
       "1      0\n",
       "106    0\n",
       "87     0\n",
       "59     0\n",
       "183    1\n",
       "150    1\n",
       "20     0\n",
       "189    1\n",
       "121    0\n",
       "162    1\n",
       "137    1\n",
       "175    1\n",
       "Name: Normal, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "display(y_pred)\n",
    "display(y_test)\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e72667",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda3ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7692307692307693\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85        28\n",
      "           1       0.67      0.36      0.47        11\n",
      "\n",
      "    accuracy                           0.77        39\n",
      "   macro avg       0.73      0.65      0.66        39\n",
      "weighted avg       0.75      0.77      0.74        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_depth = None, n_estimators = 300, min_samples_leaf = 4, min_samples_split = 10)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde0098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best Score: 0.7053763440860215\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b222e",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b91f240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 1}\n",
      "Best Score: 0.7124731182795699\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],           # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]   # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "#     'kernel': ['rbf', 'poly', 'linear']  # Kernel type\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74cc4e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717948717948718\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        28\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.72        39\n",
      "   macro avg       0.36      0.50      0.42        39\n",
      "weighted avg       0.52      0.72      0.60        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanmatichoudhary/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanmatichoudhary/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sanmatichoudhary/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', random_state=42, C = 0.1, gamma = 1)  # You can choose different kernels such as 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65f631",
   "metadata": {},
   "source": [
    "### simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a854d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 1s 5ms/step - loss: 1.4888 - accuracy: 0.5820 - val_loss: 0.8936 - val_accuracy: 0.7097\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7295 - val_loss: 0.5963 - val_accuracy: 0.7742\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.7049 - val_loss: 0.6013 - val_accuracy: 0.7419\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7295 - val_loss: 0.5773 - val_accuracy: 0.7097\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7377 - val_loss: 0.5926 - val_accuracy: 0.7097\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7295 - val_loss: 0.5878 - val_accuracy: 0.7097\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7377 - val_loss: 0.5849 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6967 - val_loss: 0.6046 - val_accuracy: 0.7742\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7459 - val_loss: 0.5926 - val_accuracy: 0.7097\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7377 - val_loss: 0.6126 - val_accuracy: 0.7097\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7377 - val_loss: 0.6113 - val_accuracy: 0.7097\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7295 - val_loss: 0.5964 - val_accuracy: 0.7097\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7459 - val_loss: 0.6103 - val_accuracy: 0.7097\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7541 - val_loss: 0.6131 - val_accuracy: 0.7097\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7377 - val_loss: 0.5994 - val_accuracy: 0.7097\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7623 - val_loss: 0.6210 - val_accuracy: 0.7097\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7459 - val_loss: 0.6275 - val_accuracy: 0.7419\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7459 - val_loss: 0.6044 - val_accuracy: 0.7097\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7541 - val_loss: 0.6157 - val_accuracy: 0.7097\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7459 - val_loss: 0.6336 - val_accuracy: 0.7419\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7377 - val_loss: 0.6154 - val_accuracy: 0.7097\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7623 - val_loss: 0.6097 - val_accuracy: 0.7097\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7459 - val_loss: 0.6498 - val_accuracy: 0.7419\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7705 - val_loss: 0.6054 - val_accuracy: 0.7097\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7295 - val_loss: 0.6133 - val_accuracy: 0.7097\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7623 - val_loss: 0.6084 - val_accuracy: 0.7419\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7787 - val_loss: 0.6152 - val_accuracy: 0.7097\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7705 - val_loss: 0.6138 - val_accuracy: 0.7097\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7459 - val_loss: 0.6269 - val_accuracy: 0.7097\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7377 - val_loss: 0.6437 - val_accuracy: 0.7097\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7377 - val_loss: 0.6204 - val_accuracy: 0.7097\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7459 - val_loss: 0.6225 - val_accuracy: 0.7097\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7705 - val_loss: 0.6219 - val_accuracy: 0.7097\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7787 - val_loss: 0.6172 - val_accuracy: 0.7097\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7459 - val_loss: 0.6360 - val_accuracy: 0.7419\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7623 - val_loss: 0.6333 - val_accuracy: 0.7097\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7541 - val_loss: 0.6520 - val_accuracy: 0.7419\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7541 - val_loss: 0.6282 - val_accuracy: 0.7097\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7705 - val_loss: 0.6301 - val_accuracy: 0.7097\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7623 - val_loss: 0.6596 - val_accuracy: 0.7419\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7623 - val_loss: 0.6665 - val_accuracy: 0.7097\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7623 - val_loss: 0.6569 - val_accuracy: 0.7419\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7459 - val_loss: 0.6500 - val_accuracy: 0.7419\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7787 - val_loss: 0.6780 - val_accuracy: 0.7097\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7541 - val_loss: 0.6926 - val_accuracy: 0.6774\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7623 - val_loss: 0.6590 - val_accuracy: 0.7097\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7623 - val_loss: 0.6422 - val_accuracy: 0.7097\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7787 - val_loss: 0.6737 - val_accuracy: 0.7097\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7705 - val_loss: 0.6455 - val_accuracy: 0.7419\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7623 - val_loss: 0.6620 - val_accuracy: 0.7419\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6923\n",
      "Test Loss: 0.6320127844810486, Test Accuracy: 0.692307710647583\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(4,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=4, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fad781",
   "metadata": {},
   "source": [
    "# Data Augmentation: Gaussain Noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3da10f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(X, mean=0, std=0.1):\n",
    "    noise = np.random.normal(mean, std, size=X.shape)\n",
    "    return X + noise\n",
    "# Example: Adding Gaussian noise with mean=0 and std=0.1\n",
    "X_with_gaussian_noise = add_gaussian_noise(X)\n",
    "X_augmented = pd.concat([X, X_with_gaussian_noise])\n",
    "y_augmented = pd.concat([y,y])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42, stratify = y_augmented)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc8196",
   "metadata": {},
   "source": [
    "### Logisitic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730727e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7402597402597403\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84        55\n",
      "           1       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.74        77\n",
      "   macro avg       0.69      0.59      0.59        77\n",
      "weighted avg       0.72      0.74      0.69        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9655d383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "14     0\n",
       "134    0\n",
       "177    1\n",
       "37     0\n",
       "13     0\n",
       "      ..\n",
       "180    1\n",
       "91     0\n",
       "161    1\n",
       "14     0\n",
       "171    1\n",
       "Name: Normal, Length: 77, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "Normal\n",
      "0    55\n",
      "1    22\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "display(y_pred)\n",
    "display(y_test)\n",
    "print(len(y_pred))\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b7d7d",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f2034c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Score: 0.8013749338974089\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d36e53b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91        55\n",
      "           1       0.87      0.59      0.70        22\n",
      "\n",
      "    accuracy                           0.86        77\n",
      "   macro avg       0.86      0.78      0.80        77\n",
      "weighted avg       0.86      0.86      0.85        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_depth = 10, n_estimators = 300, min_samples_leaf = 1, min_samples_split = 2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f99e8",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32424617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 1}\n",
      "Best Score: 0.889264939185616\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],           # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]   # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "#     'kernel': ['rbf', 'poly', 'linear']  # Kernel type\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6aed1fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922077922077922\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95        55\n",
      "           1       0.90      0.82      0.86        22\n",
      "\n",
      "    accuracy                           0.92        77\n",
      "   macro avg       0.91      0.89      0.90        77\n",
      "weighted avg       0.92      0.92      0.92        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', random_state=42, C = 10, gamma = 1)  # You can choose different kernels such as 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078f617",
   "metadata": {},
   "source": [
    "### simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7cb4e5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 1s 3ms/step - loss: 0.7556 - accuracy: 0.6571 - val_loss: 0.5756 - val_accuracy: 0.6129\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.6816 - val_loss: 0.5203 - val_accuracy: 0.7581\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.7143 - val_loss: 0.5317 - val_accuracy: 0.7903\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7224 - val_loss: 0.5279 - val_accuracy: 0.8065\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7347 - val_loss: 0.5238 - val_accuracy: 0.8065\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7306 - val_loss: 0.5691 - val_accuracy: 0.7097\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7184 - val_loss: 0.5333 - val_accuracy: 0.8065\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7306 - val_loss: 0.7031 - val_accuracy: 0.6452\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6735 - val_loss: 0.5643 - val_accuracy: 0.7742\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.7347 - val_loss: 0.5078 - val_accuracy: 0.7903\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.7061 - val_loss: 0.6131 - val_accuracy: 0.6935\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.6980 - val_loss: 0.5260 - val_accuracy: 0.7903\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.6857 - val_loss: 0.5228 - val_accuracy: 0.7903\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7265 - val_loss: 0.5102 - val_accuracy: 0.7742\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7347 - val_loss: 0.5156 - val_accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7347 - val_loss: 0.5501 - val_accuracy: 0.7742\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7224 - val_loss: 0.5096 - val_accuracy: 0.7742\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.6939 - val_loss: 0.5040 - val_accuracy: 0.7742\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7184 - val_loss: 0.5652 - val_accuracy: 0.7581\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7184 - val_loss: 0.5051 - val_accuracy: 0.7581\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7469 - val_loss: 0.5520 - val_accuracy: 0.7903\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7347 - val_loss: 0.5448 - val_accuracy: 0.7581\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7143 - val_loss: 0.5289 - val_accuracy: 0.7742\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7633 - val_loss: 0.5403 - val_accuracy: 0.7581\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7429 - val_loss: 0.5132 - val_accuracy: 0.7742\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.7510 - val_loss: 0.5447 - val_accuracy: 0.7742\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7551 - val_loss: 0.5403 - val_accuracy: 0.7742\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7347 - val_loss: 0.5438 - val_accuracy: 0.7581\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7551 - val_loss: 0.5751 - val_accuracy: 0.7581\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7755 - val_loss: 0.5520 - val_accuracy: 0.7581\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7388 - val_loss: 0.5859 - val_accuracy: 0.7419\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7714 - val_loss: 0.5372 - val_accuracy: 0.7903\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7592 - val_loss: 0.5489 - val_accuracy: 0.7742\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7755 - val_loss: 0.5585 - val_accuracy: 0.7903\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7714 - val_loss: 0.5362 - val_accuracy: 0.7581\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7510 - val_loss: 0.5576 - val_accuracy: 0.7742\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7429 - val_loss: 0.5187 - val_accuracy: 0.7581\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7510 - val_loss: 0.5976 - val_accuracy: 0.7419\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7020 - val_loss: 0.5454 - val_accuracy: 0.7581\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7633 - val_loss: 0.5556 - val_accuracy: 0.7742\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7755 - val_loss: 0.5729 - val_accuracy: 0.7742\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7755 - val_loss: 0.5471 - val_accuracy: 0.7581\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7510 - val_loss: 0.5740 - val_accuracy: 0.7742\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7755 - val_loss: 0.5530 - val_accuracy: 0.7742\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7592 - val_loss: 0.5313 - val_accuracy: 0.7581\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7551 - val_loss: 0.5894 - val_accuracy: 0.7581\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7592 - val_loss: 0.5636 - val_accuracy: 0.7903\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7633 - val_loss: 0.5536 - val_accuracy: 0.7742\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7755 - val_loss: 0.5642 - val_accuracy: 0.7742\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7592 - val_loss: 0.5375 - val_accuracy: 0.7581\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.7273\n",
      "Test Loss: 0.6387169361114502, Test Accuracy: 0.7272727489471436\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(4,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=4, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a16708",
   "metadata": {},
   "source": [
    "# Data Augmentation: Jittering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79ee70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jittering(X, magnitude=0.1):\n",
    "    jitter = np.random.uniform(-magnitude, magnitude, size=X.shape)\n",
    "    return X + jitter\n",
    "\n",
    "# Example: Adding jittering with magnitude=0.1\n",
    "X_with_jittering = add_jittering(X)\n",
    "\n",
    "X_augmented = pd.concat([X, X_with_jittering])\n",
    "y_augmented = pd.concat([y,y])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42, stratify = y_augmented)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd0798",
   "metadata": {},
   "source": [
    "### Logisitic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c68ed7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7402597402597403\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84        55\n",
      "           1       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.74        77\n",
      "   macro avg       0.69      0.59      0.59        77\n",
      "weighted avg       0.72      0.74      0.69        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0576e7d",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e903655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.8079851930195664\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "084256e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91        55\n",
      "           1       0.87      0.59      0.70        22\n",
      "\n",
      "    accuracy                           0.86        77\n",
      "   macro avg       0.86      0.78      0.80        77\n",
      "weighted avg       0.86      0.86      0.85        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_depth = 10, n_estimators = 100, min_samples_leaf = 1, min_samples_split = 2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60793485",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eaf26dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 1}\n",
      "Best Score: 0.889264939185616\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],           # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]   # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "#     'kernel': ['rbf', 'poly', 'linear']  # Kernel type\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8657aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.922077922077922\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95        55\n",
      "           1       0.90      0.82      0.86        22\n",
      "\n",
      "    accuracy                           0.92        77\n",
      "   macro avg       0.91      0.89      0.90        77\n",
      "weighted avg       0.92      0.92      0.92        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', random_state=42, C = 10, gamma = 1)  # You can choose different kernels such as 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf1b519",
   "metadata": {},
   "source": [
    "### simple neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8286bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 1s 3ms/step - loss: 0.6285 - accuracy: 0.6857 - val_loss: 0.5222 - val_accuracy: 0.7581\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7184 - val_loss: 0.5025 - val_accuracy: 0.7581\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7020 - val_loss: 0.5637 - val_accuracy: 0.7581\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7429 - val_loss: 0.5849 - val_accuracy: 0.7419\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7184 - val_loss: 0.5087 - val_accuracy: 0.7742\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7184 - val_loss: 0.5380 - val_accuracy: 0.7742\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7429 - val_loss: 0.5218 - val_accuracy: 0.7581\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7469 - val_loss: 0.5546 - val_accuracy: 0.7581\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7388 - val_loss: 0.5363 - val_accuracy: 0.7742\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7347 - val_loss: 0.6574 - val_accuracy: 0.7742\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7388 - val_loss: 0.5328 - val_accuracy: 0.7742\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7429 - val_loss: 0.5361 - val_accuracy: 0.7742\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7429 - val_loss: 0.5666 - val_accuracy: 0.7742\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7469 - val_loss: 0.5405 - val_accuracy: 0.7581\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7551 - val_loss: 0.5649 - val_accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7633 - val_loss: 0.5886 - val_accuracy: 0.7581\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7551 - val_loss: 0.5648 - val_accuracy: 0.7581\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.7510 - val_loss: 0.6010 - val_accuracy: 0.7419\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7510 - val_loss: 0.6441 - val_accuracy: 0.7581\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7673 - val_loss: 0.5571 - val_accuracy: 0.7742\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7388 - val_loss: 0.5906 - val_accuracy: 0.7581\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7796 - val_loss: 0.6226 - val_accuracy: 0.7258\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7633 - val_loss: 0.6066 - val_accuracy: 0.7581\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7633 - val_loss: 0.6407 - val_accuracy: 0.7258\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7837 - val_loss: 0.7225 - val_accuracy: 0.7258\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7510 - val_loss: 0.6123 - val_accuracy: 0.7742\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7551 - val_loss: 0.5779 - val_accuracy: 0.7742\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7306 - val_loss: 0.5758 - val_accuracy: 0.7581\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7510 - val_loss: 0.7676 - val_accuracy: 0.6613\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7510 - val_loss: 0.5830 - val_accuracy: 0.7742\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7755 - val_loss: 0.5711 - val_accuracy: 0.7742\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7102 - val_loss: 0.5897 - val_accuracy: 0.7581\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7633 - val_loss: 0.5941 - val_accuracy: 0.7581\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7469 - val_loss: 0.6115 - val_accuracy: 0.7581\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7551 - val_loss: 0.6016 - val_accuracy: 0.7419\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7796 - val_loss: 0.6086 - val_accuracy: 0.7419\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7633 - val_loss: 0.6321 - val_accuracy: 0.7419\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7592 - val_loss: 0.5914 - val_accuracy: 0.7419\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7592 - val_loss: 0.5732 - val_accuracy: 0.7581\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7469 - val_loss: 0.5982 - val_accuracy: 0.7581\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7673 - val_loss: 0.5882 - val_accuracy: 0.7581\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7755 - val_loss: 0.6406 - val_accuracy: 0.7581\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7551 - val_loss: 0.5840 - val_accuracy: 0.7742\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7388 - val_loss: 0.5834 - val_accuracy: 0.7742\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7633 - val_loss: 0.5833 - val_accuracy: 0.7581\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7633 - val_loss: 0.6031 - val_accuracy: 0.7419\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7796 - val_loss: 0.6105 - val_accuracy: 0.7419\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7469 - val_loss: 0.5868 - val_accuracy: 0.7581\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7633 - val_loss: 0.6051 - val_accuracy: 0.7581\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7714 - val_loss: 0.6148 - val_accuracy: 0.7581\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.6883\n",
      "Test Loss: 0.6772850751876831, Test Accuracy: 0.6883116960525513\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(4,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=4, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e323fd89",
   "metadata": {},
   "source": [
    "# Data Augmentation: GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d92092ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 0, Discriminator Loss: 0.627822995185852, Generator Loss: 0.6596895456314087\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Convergence reached at epoch 5\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Epoch: 0, Discriminator Loss: 0.678354024887085, Generator Loss: 0.6864889860153198\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Convergence reached at epoch 5\n",
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.45644355, 0.44533405, 0.30644184, 0.55709916],\n",
       "       [0.5169408 , 0.6264897 , 0.43746346, 0.3406163 ],\n",
       "       [0.70144   , 0.6294563 , 0.3164919 , 0.43979266],\n",
       "       ...,\n",
       "       [0.565954  , 0.47399348, 0.2992886 , 0.5573756 ],\n",
       "       [0.68463886, 0.45058566, 0.2922033 , 0.42820233],\n",
       "       [0.46010318, 0.5363767 , 0.4733422 , 0.59058756]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Generator network\n",
    "def build_generator(latent_dim, num_features):\n",
    "    model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_dim=latent_dim),  # Increase the number of neurons and depth\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1024, activation='relu'),  # Increase the number of neurons and depth\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(512, activation='relu'),  # Increase the number of neurons and depth\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(num_features, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_discriminator(num_features):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(1024, activation='relu', input_dim=num_features),  # Increase the number of neurons and depth\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='relu'),  # Increase the number of neurons and depth\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),  # Increase the number of neurons and depth\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = keras.Sequential([generator, discriminator])\n",
    "    return model\n",
    "\n",
    "# Training GAN\n",
    "def train_gan(generator, discriminator, gan, X_train, y_train, latent_dim, num_epochs=100, batch_size=32, logging_interval=1000, convergence_threshold=0.1, convergence_patience=5):\n",
    "    best_discriminator_loss = float('inf')\n",
    "    best_generator_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Generate fake samples\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        generated_data = generator.predict(noise)\n",
    "        \n",
    "        # Select a random batch of real samples\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_samples = X_train.iloc[idx]\n",
    "        \n",
    "        # Concatenate real and fake samples\n",
    "        X = np.concatenate([real_samples, generated_data])\n",
    "        \n",
    "        # Labels for real and fake samples\n",
    "        y_real = np.ones((batch_size, 1))\n",
    "        y_fake = np.zeros((batch_size, 1))\n",
    "        y = np.concatenate([y_real, y_fake])\n",
    "        \n",
    "        # Train discriminator\n",
    "        discriminator_loss = discriminator.train_on_batch(X, y)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        generator_loss = gan.train_on_batch(noise, y_real)\n",
    "        \n",
    "        # Logging\n",
    "        if epoch % logging_interval == 0:\n",
    "            print(f\"Epoch: {epoch}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")\n",
    "        \n",
    "        # Convergence monitoring\n",
    "        if discriminator_loss < best_discriminator_loss - convergence_threshold and generator_loss < best_generator_loss - convergence_threshold:\n",
    "            best_discriminator_loss = discriminator_loss\n",
    "            best_generator_loss = generator_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= convergence_patience:\n",
    "            print(f\"Convergence reached at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# Train GAN with convergence monitoring\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_gan(generator, discriminator, gan, X_train, y_train, latent_dim)\n",
    "\n",
    "\n",
    "# Generate synthetic samples\n",
    "def generate_samples(generator, latent_dim, num_samples):\n",
    "    noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "    generated_data = generator.predict(noise)\n",
    "    return generated_data\n",
    "\n",
    "# Load data\n",
    "# Assuming your DataFrame is named df, and the target column is named 'abnormal'\n",
    "# Drop the target column to get the feature data\n",
    "# X = df.drop(columns=['normal']).values\n",
    "# y = df['normal'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "# Parameters\n",
    "latent_dim = 100\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Build and compile models\n",
    "generator = build_generator(latent_dim, num_features)\n",
    "discriminator = build_discriminator(num_features)\n",
    "gan = build_gan(generator, discriminator)\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "discriminator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "# discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train GAN\n",
    "train_gan(generator, discriminator, gan, X_train, y_train, latent_dim)\n",
    "\n",
    "# Generate samples\n",
    "generated_samples = generate_samples(generator, latent_dim, 1000)\n",
    "\n",
    "# Plot generated samples\n",
    "# plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], color='blue', alpha=0.5, label='Real Data')\n",
    "# plt.scatter(generated_samples[:, 0], generated_samples[:, 1], color='red', alpha=0.5, label='Generated Data')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "display(generated_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc964323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], color='blue', alpha=0.5, label='Real Data')\n",
    "plt.scatter(generated_samples[:, 0], generated_samples[:, 1], color='red', alpha=0.5, label='Generated Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee5c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37172f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64679a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a28e9843",
   "metadata": {},
   "source": [
    "# Stratifying/Splitting Train Equally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b4822c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AmplitudePrimary</th>\n",
       "      <th>AmplitudeSecondary</th>\n",
       "      <th>Latency</th>\n",
       "      <th>CorrectiveSaccade</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.905335</td>\n",
       "      <td>0.907229</td>\n",
       "      <td>0.124998</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.381435</td>\n",
       "      <td>0.563108</td>\n",
       "      <td>0.341670</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.415535</td>\n",
       "      <td>1.097195</td>\n",
       "      <td>0.308346</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.173487</td>\n",
       "      <td>1.182019</td>\n",
       "      <td>0.175026</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.801426</td>\n",
       "      <td>7.733378</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3.948713</td>\n",
       "      <td>3.948713</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>14.329194</td>\n",
       "      <td>3.160185</td>\n",
       "      <td>0.125025</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>19.042962</td>\n",
       "      <td>3.035957</td>\n",
       "      <td>0.525034</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.762336</td>\n",
       "      <td>2.942543</td>\n",
       "      <td>0.325038</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>31.529303</td>\n",
       "      <td>1.850806</td>\n",
       "      <td>0.508392</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AmplitudePrimary  AmplitudeSecondary   Latency  CorrectiveSaccade  Normal\n",
       "0            7.905335            0.907229  0.124998                  7       0\n",
       "1           17.381435            0.563108  0.341670                 13       0\n",
       "2           29.415535            1.097195  0.308346                 16       0\n",
       "3           10.173487            1.182019  0.175026                  9       0\n",
       "4            6.801426            7.733378  0.391700                 28       0\n",
       "..                ...                 ...       ...                ...     ...\n",
       "187          3.948713            3.948713  0.033335                 16       1\n",
       "188         14.329194            3.160185  0.125025                  6       1\n",
       "189         19.042962            3.035957  0.525034                  5       1\n",
       "190          1.762336            2.942543  0.325038                 15       1\n",
       "191         31.529303            1.850806  0.508392                 20       1\n",
       "\n",
       "[192 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"TestDataCompiled.csv\")\n",
    "df.columns = ['AmplitudePrimary', 'AmplitudeSecondary', 'Latency', \"CorrectiveSaccade\", \"Normal\"]\n",
    "display(df)\n",
    "df[\"Normal\"].value_counts()\n",
    "\n",
    "y = df.Normal\n",
    "X = df.drop('Normal', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa32bc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192,)\n",
      "Normal\n",
      "0    137\n",
      "1     55\n",
      "Name: count, dtype: int64\n",
      "(88, 4)\n",
      "(104, 4)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "print(y.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "\n",
    "train_y_count = int(0.8*55)\n",
    "arr_0 = y[y==0].index\n",
    "arr_1 = y[y==1].index\n",
    "\n",
    "indicies_0_train = np.random.choice(arr_0, size=train_y_count, replace=False)\n",
    "indicies_1_train = np.random.choice(arr_1, size=train_y_count, replace=False)\n",
    "concatenated_array = np.concatenate((indicies_0_train, indicies_1_train), axis=0)\n",
    "\n",
    "X_train = X.iloc[concatenated_array]\n",
    "y_train = y.iloc[concatenated_array]\n",
    "X_test = X.drop(concatenated_array)\n",
    "y_test = y.drop(concatenated_array)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8664363",
   "metadata": {},
   "source": [
    "## No Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c5b0f",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2be2188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Score: 0.5352941176470589\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "910adefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5192307692307693\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.51      0.65        93\n",
      "           1       0.13      0.64      0.22        11\n",
      "\n",
      "    accuracy                           0.52       104\n",
      "   macro avg       0.53      0.57      0.44       104\n",
      "weighted avg       0.84      0.52      0.61       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_depth = None, n_estimators = 200, min_samples_leaf = 1, min_samples_split = 5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce77a3a",
   "metadata": {},
   "source": [
    "## Data Augmentation: Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c66a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(X, mean=0, std=0.1):\n",
    "    noise = np.random.normal(mean, std, size=X.shape)\n",
    "    return X + noise\n",
    "# Example: Adding Gaussian noise with mean=0 and std=0.1\n",
    "X_with_gaussian_noise = add_gaussian_noise(X)\n",
    "X_augmented = pd.concat([X, X_with_gaussian_noise])\n",
    "y_augmented = pd.concat([y,y])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42, stratify = y_augmented)\n",
    "\n",
    "train_y_count = int(0.8*55)\n",
    "arr_0 = y_augmented[y_augmented==0].index\n",
    "arr_1 = y_augmented[y_augmented==1].index\n",
    "\n",
    "indicies_0_train = np.random.choice(arr_0, size=train_y_count, replace=False)\n",
    "indicies_1_train = np.random.choice(arr_1, size=train_y_count, replace=False)\n",
    "concatenated_array = np.concatenate((indicies_0_train, indicies_1_train), axis=0)\n",
    "\n",
    "X_train = X_augmented.iloc[concatenated_array]\n",
    "y_train = y_augmented.iloc[concatenated_array]\n",
    "X_test = X_augmented.drop(concatenated_array)\n",
    "y_test = y_augmented.drop(concatenated_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d780398f",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a40a4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 0.1}\n",
      "Best Score: 0.6712418300653595\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],           # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]   # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "#     'kernel': ['rbf', 'poly', 'linear']  # Kernel type\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a69a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5504201680672269\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69       190\n",
      "           1       0.16      0.29      0.21        48\n",
      "\n",
      "    accuracy                           0.55       238\n",
      "   macro avg       0.47      0.45      0.45       238\n",
      "weighted avg       0.65      0.55      0.59       238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', random_state=42, C = 10, gamma = 0.1)  # You can choose different kernels such as 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c822d6d",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "756aeebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.7509803921568627\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdff9782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5798319327731093\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.62      0.70       190\n",
      "           1       0.22      0.44      0.30        48\n",
      "\n",
      "    accuracy                           0.58       238\n",
      "   macro avg       0.52      0.53      0.50       238\n",
      "weighted avg       0.69      0.58      0.62       238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_depth = None, n_estimators = 100, min_samples_leaf = 2, min_samples_split = 2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdcc281",
   "metadata": {},
   "source": [
    "## Data Augmentation: Jittering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dd55642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jittering(X, magnitude=0.1):\n",
    "    jitter = np.random.uniform(-magnitude, magnitude, size=X.shape)\n",
    "    return X + jitter\n",
    "\n",
    "# Example: Adding jittering with magnitude=0.1\n",
    "X_with_jittering = add_jittering(X)\n",
    "X_augmented = pd.concat([X, X_with_jittering])\n",
    "y_augmented = pd.concat([y,y])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42, stratify = y_augmented)\n",
    "\n",
    "train_y_count = int(0.8*55)\n",
    "arr_0 = y_augmented[y_augmented==0].index\n",
    "arr_1 = y_augmented[y_augmented==1].index\n",
    "\n",
    "indicies_0_train = np.random.choice(arr_0, size=train_y_count, replace=False)\n",
    "indicies_1_train = np.random.choice(arr_1, size=train_y_count, replace=False)\n",
    "concatenated_array = np.concatenate((indicies_0_train, indicies_1_train), axis=0)\n",
    "\n",
    "X_train = X_augmented.iloc[concatenated_array]\n",
    "y_train = y_augmented.iloc[concatenated_array]\n",
    "X_test = X_augmented.drop(concatenated_array)\n",
    "y_test = y_augmented.drop(concatenated_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaffa347",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a0a27e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'gamma': 1}\n",
      "Best Score: 0.6464052287581699\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],           # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001]   # Kernel coefficient for 'rbf' and 'poly' kernels\n",
    "#     'kernel': ['rbf', 'poly', 'linear']  # Kernel type\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67d9b3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7920353982300885\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       188\n",
      "           1       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.79       226\n",
      "   macro avg       0.41      0.48      0.44       226\n",
      "weighted avg       0.69      0.79      0.74       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', random_state=42, C = 1, gamma = 1)  # You can choose different kernels such as 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7695b",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8b0fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score: 0.6372549019607844\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af4b2386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5265486725663717\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.53      0.65       188\n",
      "           1       0.18      0.53      0.27        38\n",
      "\n",
      "    accuracy                           0.53       226\n",
      "   macro avg       0.51      0.53      0.46       226\n",
      "weighted avg       0.73      0.53      0.59       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_depth = None, n_estimators = 100, min_samples_leaf = 1, min_samples_split = 2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f8d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
